{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ensure you successfully run and test a few models in __llm_testing.ipynb__ before implementing a RAG pattern**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### RAG Pattern Overview \n",
    "\n",
    "RAG stands for Retrieval Augmented Generation. A RAG pattern is essentially a way to augment our models response by grounding it in some sort of information retrieved from a database (typically a chunk of a document). \n",
    "\n",
    "A general flow for the RAG pattern is; \n",
    "1. A user enters a question or a prompt \n",
    "2. The users query is searched for in a vector database \n",
    "3. The documents retrieved from the vector database are passed to GenAI alongside a prompt\n",
    "    i. (for example, \"Your job is to summarize the chunks of the documents\")\n",
    "4. Our generative AI provides us a response grounded in the document. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai.foundation_models import Model\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "## DO NOT SHARE .env ANYWHERE\n",
    "load_dotenv()\n",
    "project_id = os.getenv('PROJECT_ID')\n",
    "api_key=os.getenv('GENAI_API_KEY')\n",
    "url=os.getenv('GENAI_URL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky appears blue due to a phenomenon called Rayleigh scattering. When sunlight reaches Earth's atmosphere, it is made up of different wavelengths, including red, orange, yellow, green, blue, and violet. Shorter-wavelength light, such as blue and violet, is scattered in all directions more than longer-wavelength light. As a result, the scattered blue and violet light reach our eyes from all directions, making the sky appear blue. This scattering also causes the sun to appear yellow during sunrise and sunset, as the shorter-wavelength light is scattered away from our line of sight, leaving the longer-wavelength light, like red and orange, to dominate.\n"
     ]
    }
   ],
   "source": [
    "# Modify your prompt below. \n",
    "prompt = '''\n",
    "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "Why is the sky blue?\n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "'''\n",
    "\n",
    "# Tokens can be thought of as part words - almost like syllables. \n",
    "# Larger MAX_NEW_TOKENS will allow the models to generate longer responses.\n",
    "# Each model has a unique context window for tokens - for llama3 it is 8000 tokens. \n",
    "generate_params = {\n",
    "            GenParams.MAX_NEW_TOKENS: 300\n",
    "        }\n",
    "\n",
    "## Model choices:\n",
    "# - ibm/granite-34b-code-instruct\n",
    "# - meta-llama/llama-3-70b-instruct\n",
    "# - ibm/granite-8b-code-instruct\n",
    "# - meta-llama/llama-3-8b-instruct\n",
    "# - ibm/granite-13b-chat-v2\n",
    "\n",
    "model = Model(\n",
    "    model_id=\"ibm/granite-13b-chat-v2\",\n",
    "    params=generate_params,\n",
    "    credentials={\n",
    "        \"apikey\": f\"{api_key}\",\n",
    "        \"url\": f\"{url}\"\n",
    "    },\n",
    "    project_id=project_id\n",
    "    )\n",
    "\n",
    "\n",
    "## For testing\n",
    "generated_response = model.generate(prompt=prompt)\n",
    "print(generated_response['results'][0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Set up vector DB\n",
    "\n",
    "- The vector DB will store all your documents after they are chunked \n",
    "- It will be searched by the LLM to find appropriate responses to queries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "## We will be using ChromaDB but feel free to try other vector DBs such as FAISS, Milvus, ElasticSearch...etc.\n",
    "\n",
    "# Instantiate database client \n",
    "chroma_client = chromadb.Client()\n",
    "\n",
    "# Create a collection to store the vectors (or get collection if it already exists)\n",
    "# NOTE: If you want to test with a fresh collection every time, use delete_collection\n",
    "collection = chroma_client.get_or_create_collection(name=\"my_collection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create embeddings\n",
    "\n",
    "- Embeddings are vectors associated with tokens from a text\n",
    "- An embedding function will take text chunks as input and output vectors to represent the tokens\n",
    "- Vectors are fed into the vector DB\n",
    "\n",
    "**Steps**\n",
    "\n",
    "1. Read pdf / document\n",
    "2. Chunk document \n",
    "3. Feed chunks to embedding function\n",
    "4. Put embeddings into vector DB\n",
    "\n",
    "**Lines for you to code are marked with <-- TODO -->**\n",
    "\n",
    "**All TODOs can be done with the existing imports. Read the documentation and resources to find what functions to use. If you would like to do your own implementation or use other libraries, feel free**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ./pdfs\\Australia_code_vol_1_dc.pdf\n",
      "Loading ./pdfs\\Australia_code_vol_2_dc.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " impossible to decode XFormObject /Fm0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ./pdfs\\Australia_code_vol_3_dc.pdf\n",
      "Loading ./pdfs\\Australia_housing_provisions_dc.pdf\n",
      "Loading ./pdfs\\Building Control Act 1989 Singapore_dc.pdf\n",
      "Loading ./pdfs\\Building Control Regulations 2003 Singapore_dc.pdf\n",
      "Loading ./pdfs\\HK_demolition_dc.pdf\n",
      "Loading ./pdfs\\HK_escalators_dc.pdf\n",
      "Loading ./pdfs\\HK_external_maintenance_dc.pdf\n",
      "Loading ./pdfs\\HK_firefighting_dc.pdf\n",
      "Loading ./pdfs\\HK_fire_escape_dc.pdf\n",
      "Loading ./pdfs\\HK_fire_resistance_dc.pdf\n",
      "Loading ./pdfs\\HK_fire_safety_dc.pdf\n",
      "Loading ./pdfs\\HK_foundations_dc.pdf\n",
      "Loading ./pdfs\\HK_glass_dc.pdf\n",
      "Loading ./pdfs\\HK_site_supervision_dc.pdf\n",
      "Loading ./pdfs\\HK_steel_dc.pdf\n",
      "Loading ./pdfs\\HK_thermal_transfer_dc.pdf\n",
      "Loading ./pdfs\\HK_wind_dc.pdf\n",
      "Loading ./pdfs\\Japan_building_standard_law_dc.pdf\n",
      "Loading ./pdfs\\London_building_act_dc.pdf\n",
      "Loading ./pdfs\\London_building_regulations_dc.pdf\n",
      "Loading ./pdfs\\Los Angeles County, CA Code of Ordinances_dc.pdf\n",
      "Loading ./pdfs\\Netherlands-2011-0212-000-EN_dc.pdf\n",
      "Loading ./pdfs\\NYC_local_laws_2023_dc.pdf\n",
      "Loading ./pdfs\\Paris_regulations_dc.pdf\n",
      "Loading ./pdfs\\singapore_building_control_buildability_regulations_dc.pdf\n",
      "Loading ./pdfs\\singapore_building_control_env_sus_regulations_dc.pdf\n",
      "Loading ./pdfs\\singapore_circular2017_dc.pdf\n",
      "Loading ./pdfs\\singapore_cop2017_dc.pdf\n",
      "Loading ./pdfs\\Toronto_Building Code Act, 1992, S.O. 1992, c. 23_dc.pdf\n",
      "Loading ./pdfs\\Toronto_O. Reg. 332_12_ BUILDING CODE_dc.pdf\n",
      "Chunking\n",
      "Storing batch 0\n",
      "Storing batch 100\n",
      "Storing batch 200\n",
      "Storing batch 300\n",
      "Storing batch 400\n",
      "Storing batch 500\n",
      "Storing batch 600\n",
      "Storing batch 700\n",
      "Storing batch 800\n",
      "Storing batch 900\n",
      "Storing batch 1000\n",
      "Storing batch 1100\n",
      "Storing batch 1200\n",
      "Storing batch 1300\n",
      "Storing batch 1400\n",
      "Storing batch 1500\n",
      "Storing batch 1600\n",
      "Storing batch 1700\n",
      "Storing batch 1800\n",
      "Storing batch 1900\n",
      "Storing batch 2000\n",
      "Storing batch 2100\n",
      "Storing batch 2200\n",
      "Storing batch 2300\n",
      "Storing batch 2400\n",
      "Storing batch 2500\n",
      "Storing batch 2600\n",
      "Storing batch 2700\n",
      "Storing batch 2800\n",
      "Storing batch 2900\n",
      "Storing batch 3000\n",
      "Storing batch 3100\n",
      "Storing batch 3200\n",
      "Storing batch 3300\n",
      "Storing batch 3400\n",
      "Storing batch 3500\n",
      "Storing batch 3600\n",
      "Storing batch 3700\n",
      "Storing batch 3800\n",
      "Storing batch 3900\n",
      "Storing batch 4000\n",
      "Storing batch 4100\n",
      "Storing batch 4200\n",
      "Storing batch 4300\n",
      "Storing batch 4400\n",
      "Storing batch 4500\n",
      "Storing batch 4600\n",
      "Storing batch 4700\n",
      "Storing batch 4800\n",
      "Storing batch 4900\n",
      "Storing batch 5000\n",
      "Storing batch 5100\n",
      "Storing batch 5200\n",
      "Storing batch 5300\n",
      "Storing batch 5400\n",
      "Storing batch 5500\n",
      "Storing batch 5600\n",
      "Storing batch 5700\n",
      "Storing batch 5800\n",
      "Storing batch 5900\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from ibm_watsonx_ai.metanames import EmbedTextParamsMetaNames as EmbedParams\n",
    "from langchain_ibm import WatsonxEmbeddings\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "import chromadb\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "## Set up embedding function\n",
    "# embedding params\n",
    "embed_params = {\n",
    "            EmbedParams.TRUNCATE_INPUT_TOKENS: 3,\n",
    "            EmbedParams.RETURN_OPTIONS: {\n",
    "            'input_text': True\n",
    "            }\n",
    "        }\n",
    "\n",
    "# embedding function\n",
    "watsonx_embedding = WatsonxEmbeddings(\n",
    "    model_id=\"ibm/slate-125m-english-rtrvr\",\n",
    "    url=f\"{url}\",\n",
    "    apikey=f\"{api_key}\",\n",
    "    project_id=project_id,\n",
    "    params=embed_params,\n",
    ")\n",
    "\n",
    "### Extract text from pdfs\n",
    "## 1. Parse PDFs \n",
    "\n",
    "test_file = \"da-vinci-test.pdf\"  # File to test your rag pattern\n",
    "\n",
    "all_files = os.listdir(path='./pdfs')  # List of all PDF files to use in your implementation (construction codes)\n",
    "\n",
    "\n",
    "## Load the pdf file (start with test file)\n",
    "documents = []\n",
    "for file_name in all_files:\n",
    "    file_path = os.path.join(\"./pdfs\", file_name)\n",
    "    print(\"Loading\", file_path)\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    document = loader.load()  # loads file from loader\n",
    "    documents.extend(document)\n",
    "\n",
    "\n",
    "## 2. chunk text \n",
    "print(\"Chunking\")\n",
    "## Split the text\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "chunks = text_splitter.split_documents(document)\n",
    "\n",
    "\n",
    "## 3. create embeddings and store in vector DB\n",
    "\n",
    "batch_size = 100\n",
    "for i in range(0, len(chunks), batch_size):\n",
    "    print(\"Storing batch\", i)\n",
    "    chunk_batch = chunks[i:i+batch_size]\n",
    "\n",
    "    # Create embeddings and store in collection\n",
    "    chroma_db = Chroma.from_documents(\n",
    "        documents=chunk_batch,\n",
    "        embedding=watsonx_embedding,\n",
    "        collection_name=\"my_collection\",\n",
    "        client=chroma_client,\n",
    "    )\n",
    "\n",
    "print(\"Done\")\n",
    "\n",
    "#### TODO: Modify steps 1 to 3 so that it works for all_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Combine elements into RAG pattern\n",
    "\n",
    "RAG patterns consist of:\n",
    "- A query\n",
    "- A model to answer the query\n",
    "- An engineered prompt for the model which asks for the query to be answered using the provided context \n",
    "- A retriever to retrieve the appropriate documents from the vector DB using the original query\n",
    "\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Query is asked\n",
    "2. Query is input to the engineered prompt\n",
    "3. Engineered prompt is asked to the model\n",
    "4. Vector DB is searched to find best answer from the provided context (done by retriever)\n",
    "5. Vector DB returns new information to the model\n",
    "6. Model generates answer to original query using the information from the vector DB \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The building regulations in Singapore are quite strict, as evidenced by the specific requirements mentioned in the context. For instance, there are restrictions on the height of buildings, clearance requirements for signs near electrical conductors, and specifications for potable water systems and leaching beds. These regulations are designed to ensure that buildings are constructed and maintained to a high standard, with a focus on safety, hygiene, and sustainability. Additionally, the regulations require that installations conform to specific standards, such as those for hot applied rubberized asphalt, sheet applied flexible polyvinyl chloride roofing membrane, asphalt shingle application, and more. This further demonstrates the strictness of the building regulations in Singapore.\n"
     ]
    }
   ],
   "source": [
    "# Helper function to combine list of docs from vector DB into a single doc\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Function to combine all elements into a complete RAG pattern\n",
    "# Returns RAG response from LLM\n",
    "def rag_query(query, retriever, model)->str:\n",
    "    \n",
    "    # Template for engineered prompt asking for a context-based answer\n",
    "    template = f\"\"\"You are an assistant for question-answering tasks. \n",
    "        Use the following pieces of retrieved context to answer the question. \n",
    "        If you don't know the answer, just say that you don't know. \n",
    "        Question: {query} \n",
    "        Context: {format_docs(retriever.invoke(query))} \n",
    "        Answer:\n",
    "        \"\"\"   \n",
    "    \n",
    "    \n",
    "    ## Generate a context based response from the LLM\n",
    "    generated_response = model.generate(prompt=template)\n",
    "    return generated_response['results'][0]['generated_text']\n",
    "\n",
    "\n",
    "### Run your implemented RAG pattern!\n",
    "\n",
    "# Instantiates a retriever from the vector DB to find appropriate context\n",
    "retriever = chroma_db.as_retriever()\n",
    "\n",
    "# Sample question for test pdf\n",
    "# Verify the answer by reading page 3 in the test pdf\n",
    "question = \"How strict is building regulation in Singapore?\"\n",
    "response = rag_query(question, retriever, model)\n",
    "\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONGRATULATIONS! ###\n",
    "\n",
    "You have created your first RAG pattern (or maybe you've done this before)! Now take this knowledge and see where you can take it to solve the brief. Feel free to look at other resources and try different things. Good luck :D\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
